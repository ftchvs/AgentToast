"""Coordinator agent that orchestrates the multi-agent news workflow."""

from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field
import logging
import asyncio
import re
import json

from agents import function_tool
from src.agents.base_agent import BaseAgent
from src.agents.news_agent import NewsAgent, NewsRequest, NewsSummary
from src.agents.writer_agent import WriterAgent, WriterInput, WriterOutput
from src.agents.analyst_agent import AnalystAgent, AnalystInput, AnalystOutput
from src.agents.fact_checker_agent import FactCheckerAgent, FactCheckerInput, FactCheckerOutput
from src.agents.trend_agent import TrendAgent, TrendInput, TrendOutput
from src.agents.finance_agent import FinanceAgent, FinanceInput, FinanceOutput, FinanceErrorOutput
from src.agents.planner_agent import PlannerAgent, PlannerInput, PlannerOutput, ProcessingPlan
from src.config import get_logger
from src.utils.tts import text_to_speech
from src.utils.tracing import tracing
from agents.tracing.traces import Trace

logger = get_logger(__name__)

class CoordinatorInput(BaseModel):
    """Input for the coordinator agent."""
    
    prompt: Optional[str] = Field(
        description="Natural language user request (e.g., 'latest tech news in the US')",
        default=None
    )
    category: str = Field(
        description="News category to fetch articles from (business, entertainment, general, health, science, sports, technology)",
        default="general"
    )
    count: int = Field(
        description="Number of articles to fetch",
        default=5
    )
    country: Optional[str] = Field(
        description="The 2-letter ISO 3166-1 code of the country (e.g., us, gb, au)",
        default=None
    )
    sources: Optional[str] = Field(
        description="A comma-separated string of news source IDs (e.g., bbc-news,cnn)",
        default=None
    )
    query: Optional[str] = Field(
        description="Keywords or phrase to search for in the news",
        default=None
    )
    ticker_symbol: Optional[str] = Field(
        description="Optional stock ticker symbol to fetch financial data for (e.g., AAPL, GOOGL)",
        default=None
    )
    voice: Optional[str] = Field(
        description="Voice to use for audio output (alloy, echo, fable, onyx, nova, shimmer)",
        default="alloy"
    )
    generate_audio: bool = Field(
        description="Whether to generate an audio file from the summary",
        default=True
    )
    summary_style: Optional[str] = Field(
        description="Style of the summary (formal, conversational, brief)",
        default="conversational"
    )
    analysis_depth: Optional[str] = Field(
        description="Depth of analysis (basic, moderate, deep)",
        default="moderate"
    )
    use_fact_checker: bool = Field(
        description="Whether to use the fact checker agent",
        default=True
    )
    use_trend_analyzer: bool = Field(
        description="Whether to use the trend analyzer agent",
        default=True
    )
    max_fact_claims: int = Field(
        description="Maximum number of fact claims to check",
        default=5
    )
    use_planner: bool = Field(
        description="Whether to use the PlannerAgent to determine the workflow",
        default=False
    )

class AgentResult(BaseModel):
    """Result from a single agent."""
    
    agent_name: str = Field(description="Name of the agent")
    success: bool = Field(description="Whether the agent completed successfully")
    data: Any = Field(description="Output data from the agent", default=None)
    error: Optional[str] = Field(description="Error message if the agent failed", default=None)

class CoordinatorOutput(BaseModel):
    """Output from the coordinator agent."""
    
    news_summary: Optional[str] = Field(description="Summary of the news")
    audio_file: Optional[str] = Field(description="Path to the generated audio file")
    markdown: Optional[str] = Field(description="Full markdown output")
    analysis: Optional[str] = Field(description="Analysis of the news")
    fact_check: Optional[str] = Field(description="Fact check results")
    trends: Optional[str] = Field(description="Identified trends")
    financial_data: Optional[Dict[str, Any]] = Field(description="Financial data for the requested ticker symbol", default=None)
    graph_files: Optional[List[str]] = Field(description="List of paths to generated graph files", default=None)
    agent_results: List[AgentResult] = Field(description="Results from individual agents", default_factory=list)
    processing_plan: Optional[ProcessingPlan] = Field(description="The plan generated by PlannerAgent, if used", default=None)

class CoordinatorAgent:
    """Agent that coordinates the multi-agent news workflow."""
    
    def __init__(self,
                 verbose: bool = False,
                 model: str = None,
                 temperature: Optional[float] = None,
                 news_model_override: Optional[str] = None,
                 analyst_model_override: Optional[str] = None,
                 factchecker_model_override: Optional[str] = None,
                 trend_model_override: Optional[str] = None,
                 writer_model_override: Optional[str] = None,
                 finance_model_override: Optional[str] = None,
                 planner_model_override: Optional[str] = None):
        """Initialize the coordinator agent and its sub-agents."""
        self.verbose = verbose
        self.model = model # Default/fallback model
        self.temperature = temperature
        self.model_overrides = {
            "NewsAgent": news_model_override,
            "AnalystAgent": analyst_model_override,
            "FactCheckerAgent": factchecker_model_override,
            "TrendAgent": trend_model_override,
            "WriterAgent": writer_model_override,
            "FinanceAgent": finance_model_override,
            "PlannerAgent": planner_model_override
        }
        logger.info(f"CoordinatorAgent initialized with default model: {self.model}")
        active_overrides = {k: v for k, v in self.model_overrides.items() if v}
        if active_overrides:
            logger.info(f"  Model overrides: {active_overrides}")

        # Instantiate sub-agents
        self.news_agent = NewsAgent(
            verbose=self.verbose,
            model=self._get_agent_model("NewsAgent"),
            temperature=self.temperature
        )
        self.writer_agent = WriterAgent(
            verbose=self.verbose,
            model=self._get_agent_model("WriterAgent"),
            temperature=self.temperature
        )
        self.analyst_agent = AnalystAgent(
            verbose=self.verbose,
            model=self._get_agent_model("AnalystAgent"),
            temperature=self.temperature
        )
        self.fact_checker_agent = FactCheckerAgent(
            verbose=self.verbose,
            model=self._get_agent_model("FactCheckerAgent"),
            temperature=self.temperature
        )
        self.trend_agent = TrendAgent(
            verbose=self.verbose,
            model=self._get_agent_model("TrendAgent"),
            temperature=self.temperature
        )
        self.finance_agent = FinanceAgent(
            verbose=self.verbose,
            model=self._get_agent_model("FinanceAgent"),
            temperature=self.temperature
        )
        self.planner_agent = PlannerAgent(
            verbose=self.verbose,
            model=self._get_agent_model("PlannerAgent"),
            temperature=self.temperature
        )
        logger.info("Sub-agents initialized.")

    def _get_agent_model(self, agent_name: str) -> str:
        """Get the appropriate model for a given agent, considering overrides."""
        return self.model_overrides.get(agent_name) or self.model

    async def _run_planner_agent(self, input_data: CoordinatorInput, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the PlannerAgent."""
        logger.info("Starting PlannerAgent")
        agent_name = "PlannerAgent"
        try:
            planner_input = PlannerInput(
                categories=[input_data.category] if input_data.category else [], # Planner expects list
                count=input_data.count,
                voice=input_data.voice
            )
            planner_result: PlannerOutput = await self.planner_agent.run(planner_input, parent_trace=parent_trace)
            
            if planner_result.success:
                logger.info("PlannerAgent finished successfully.")
                return AgentResult(agent_name=agent_name, success=True, data=planner_result) # data is PlannerOutput
            else:
                logger.error(f"PlannerAgent returned failure: {planner_result.error}")
                return AgentResult(agent_name=agent_name, success=False, error=planner_result.error)
        except Exception as e:
            logger.error(f"Error running PlannerAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_news_agent(self, input_data: CoordinatorInput, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the NewsAgent."""
        logger.info(f"Starting NewsAgent for category: {input_data.category}")
        agent_name = "NewsAgent"
        try:
            news_input = NewsRequest(
                category=input_data.category,
                count=input_data.count,
                country=input_data.country,
                sources=input_data.sources,
                query=input_data.query,
                voice=input_data.voice,
                # Disable audio generation here - we'll handle it at the end
                generate_audio=False
            )
            # Run NewsAgent with parent trace context
            news_result: NewsSummary = await self.news_agent.run(news_input, parent_trace=parent_trace)
            logger.info(f"NewsAgent finished successfully for category: {news_result.category if news_result else 'N/A'}")
            return AgentResult(agent_name=agent_name, success=True, data=news_result)
        except Exception as e:
            logger.error(f"Error running NewsAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_finance_agent(self, ticker_symbol: str, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the FinanceAgent."""
        logger.info(f"Starting FinanceAgent for ticker: {ticker_symbol}")
        agent_name = "FinanceAgent"
        try:
            finance_input = FinanceInput(ticker_symbol=ticker_symbol)
            finance_result = await self.finance_agent.run(finance_input, parent_trace=parent_trace)

            if isinstance(finance_result, FinanceErrorOutput):
                logger.error(f"FinanceAgent returned an error: {finance_result.error}")
                return AgentResult(agent_name=agent_name, success=False, error=finance_result.error)
            elif isinstance(finance_result, FinanceOutput):
                 logger.info(f"FinanceAgent finished successfully for ticker: {ticker_symbol}")
                 # Convert Pydantic model to dict before returning
                 return AgentResult(agent_name=agent_name, success=True, data=finance_result.model_dump())
            else:
                 logger.error(f"FinanceAgent returned unexpected result type: {type(finance_result)}")
                 return AgentResult(agent_name=agent_name, success=False, error="Unexpected result type from FinanceAgent")

        except Exception as e:
            logger.error(f"Error running FinanceAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_writer_agent(self, category: str, articles: List[Dict], style: str, analysis: Optional[str] = None, trends: Optional[str] = None, financial_data: Optional[Dict] = None, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the WriterAgent."""
        logger.info(f"Starting WriterAgent for category: {category} with style: {style}")
        agent_name = "WriterAgent"
        try:
            writer_input = WriterInput(
                category=category,
                articles=articles,
                summary_style=style,
                analysis=analysis,
                trends=trends,
                financial_data=financial_data
            )
            writer_result: WriterOutput = await self.writer_agent.run(writer_input, parent_trace=parent_trace)
            logger.info(f"WriterAgent finished successfully.")
            # Assuming WriterOutput has 'summary' and 'markdown' fields
            return AgentResult(agent_name=agent_name, success=True, data=writer_result)
        except Exception as e:
            logger.error(f"Error running WriterAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_analyst_agent(self, category: str, articles: List[Dict], summary: str, depth: str, financial_data: Optional[Dict] = None, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the AnalystAgent."""
        logger.info(f"Starting AnalystAgent for category: {category} with depth: {depth}")
        agent_name = "AnalystAgent"
        try:
            analyst_input = AnalystInput(
                category=category,
                articles=articles,
                summary=summary,
                analysis_depth=depth,
                financial_data=financial_data
            )
            analyst_result: AnalystOutput = await self.analyst_agent.run(analyst_input, parent_trace=parent_trace)
            logger.info(f"AnalystAgent finished successfully.")
            # Assuming AnalystOutput has 'analysis' field
            return AgentResult(agent_name=agent_name, success=True, data=analyst_result)
        except Exception as e:
            logger.error(f"Error running AnalystAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_fact_checker_agent(self, articles: List[Dict], summary: str, max_claims: int, parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the FactCheckerAgent."""
        logger.info(f"Starting FactCheckerAgent (max claims: {max_claims})")
        agent_name = "FactCheckerAgent"
        try:
            fact_checker_input = FactCheckerInput(
                articles=articles,
                summary=summary,
                max_claims=max_claims
            )
            fact_checker_result: FactCheckerOutput = await self.fact_checker_agent.run(fact_checker_input, parent_trace=parent_trace)
            logger.info(f"FactCheckerAgent finished successfully.")
            # Assuming FactCheckerOutput has 'fact_check_results' field
            return AgentResult(agent_name=agent_name, success=True, data=fact_checker_result)
        except Exception as e:
            logger.error(f"Error running FactCheckerAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def _run_trend_agent(self, category: str, articles: List[Dict], parent_trace: Optional[Trace] = None) -> AgentResult:
        """Runs the TrendAgent."""
        logger.info(f"Starting TrendAgent for category: {category}")
        agent_name = "TrendAgent"
        try:
            trend_input = TrendInput(
                category=category,
                articles=articles
            )
            trend_result: TrendOutput = await self.trend_agent.run(trend_input, parent_trace=parent_trace)
            logger.info(f"TrendAgent finished successfully.")
            # Assuming TrendOutput has 'identified_trends' field
            return AgentResult(agent_name=agent_name, success=True, data=trend_result)
        except Exception as e:
            logger.error(f"Error running TrendAgent: {str(e)}")
            return AgentResult(agent_name=agent_name, success=False, error=str(e))

    async def run(self, input_data: CoordinatorInput) -> CoordinatorOutput:
        """
        Run the multi-agent news workflow.
        
        Args:
            input_data: The input parameters
            
        Returns:
            A comprehensive output with results from all agents
        """
        # Start the top-level trace for the coordinator
        with tracing.trace("CoordinatorAgent_run", {"input": input_data.model_dump()}) as coordinator_trace:
            agent_results: List[AgentResult] = []
            articles_data = []
            news_summary_text = None
            full_markdown = None
            analysis_text = None
            fact_check_text = None
            trends_text = None
            financial_data_dict = None
            graph_files_list = []
            audio_file_path = None
            processing_plan: Optional[ProcessingPlan] = None
            execute_default_workflow = True # Flag to control workflow execution

            # Step 0.5: Parse Prompt if provided (overrides other inputs)
            if input_data.prompt:
                logger.info(f"Parsing prompt: '{input_data.prompt}'")
                parsed_params = await self._parse_prompt(input_data.prompt, parent_trace=coordinator_trace)
                if parsed_params:
                    logger.info(f"Applying parsed parameters: {parsed_params}")
                    # Update input_data with parsed values (carefully, only update if key exists)
                    # Pydantic models are immutable by default, so create a new one or use model_copy
                    update_dict = {k: v for k, v in parsed_params.items() if v is not None and hasattr(input_data, k)}
                    input_data = input_data.model_copy(update=update_dict)
            # Optional Step 0: Run PlannerAgent
            if input_data.use_planner:
                logger.info("PlannerAgent requested. Generating plan...")
                planner_agent_result = await self._run_planner_agent(input_data, parent_trace=coordinator_trace)
                agent_results.append(planner_agent_result)

                if planner_agent_result.success and planner_agent_result.data and planner_agent_result.data.plan:
                    processing_plan = planner_agent_result.data.plan
                    logger.info(f"PlannerAgent generated plan with {len(processing_plan.steps)} steps.")
                    execute_default_workflow = False # Use the generated plan instead

                    # --- Execute Planned Workflow --- 
                    # TODO: Implement plan execution logic here
                    # This will involve iterating through processing_plan.steps
                    # and calling the appropriate _run_*_agent methods based on step.action
                    # Need to manage data dependencies between steps (e.g., pass articles to writer)
                    logger.warning("Planner execution logic not yet implemented. Falling back to default workflow for now.")
                    execute_default_workflow = True # TEMPORARY FALLBACK

                else:
                    logger.error("PlannerAgent failed or returned no plan. Falling back to default workflow.")
                    # Keep execute_default_workflow = True

            # --- Default Workflow (if planner not used or failed/no plan) ---
            if execute_default_workflow:
                logger.info("Executing default workflow.")

            # Step 1: Fetch news
            news_agent_result = await self._run_news_agent(input_data, parent_trace=coordinator_trace)
            agent_results.append(news_agent_result)

            if news_agent_result.success:
                news_summary_obj: Optional[NewsSummary] = news_agent_result.data
                # Directly extract article data if NewsSummary object is valid
                if news_summary_obj and hasattr(news_summary_obj, 'articles'):
                    articles_data = [
                        {
                            "title": article.title,
                            "description": article.description,
                            "source": article.source,
                            "url": article.url,
                            "published_at": article.published_at
                        }
                        for article in news_summary_obj.articles
                    ]
                    logger.info(f"Extracted {len(articles_data)} articles from NewsAgent result.")
                else:
                    # Handle case where NewsAgent succeeded but returned invalid data structure or None
                    logger.error("NewsAgent succeeded but returned no valid article data.")
                    articles_data = [] # Ensure it's an empty list
                    if news_summary_obj and hasattr(news_summary_obj, 'summary') and "Error:" in news_summary_obj.summary:
                         # Log the error summary from NewsAgent if available
                         logger.error(f"NewsAgent processing error: {news_summary_obj.summary}")
                         # Propagate the error message somewhat?
                         # For now, just log it. Coordinator will proceed without articles.
            else:
                logger.error("NewsAgent failed. Unable to proceed with main workflow.")
                # Return early with failure indication
                return CoordinatorOutput(agent_results=agent_results)

            # Step 2: Fetch financial data (optional)
            if input_data.ticker_symbol:
                finance_agent_result = await self._run_finance_agent(input_data.ticker_symbol, parent_trace=coordinator_trace)
                agent_results.append(finance_agent_result)
                if finance_agent_result.success:
                    financial_data_dict = finance_agent_result.data # This should be a dict now
                    # Extract graph file paths if they exist in the FinanceOutput data
                    graph_files_list = financial_data_dict.get("graph_files", [])
                    # Remove graph_files from the main financial_data dict if needed
                    if "graph_files" in financial_data_dict:
                        del financial_data_dict["graph_files"]
                else:
                     logger.warning(f"FinanceAgent failed for {input_data.ticker_symbol}: {finance_agent_result.error}")
                     # Continue without financial data

            # Ensure we have some articles before proceeding
            if not articles_data:
                logger.error("No articles available to process. Skipping further steps.")
                return CoordinatorOutput(agent_results=agent_results)


            # Step 3: Run Writer Agent (initial summary based on news)
            # We run the writer first to get a basic summary, which might be needed by other agents
            writer_result_initial = await self._run_writer_agent(
                category=input_data.category,
                articles=articles_data,
                style=input_data.summary_style,
                # Pass financial data if available, even for the initial run
                financial_data=financial_data_dict,
                parent_trace=coordinator_trace
            )
            agent_results.append(writer_result_initial)

            if writer_result_initial.success:
                writer_output_initial: WriterOutput = writer_result_initial.data
                news_summary_text = writer_output_initial.summary # Get initial summary
                full_markdown = writer_output_initial.markdown # Get initial markdown
                logger.info("Initial summary generated by WriterAgent.")
            else:
                logger.error("Initial WriterAgent run failed. Summary will be missing.")
                # Continue, but summary-dependent steps might fail

            # Step 4: Run parallel analyses (Analyst, Fact Checker, Trend)
            parallel_tasks = []
            if news_summary_text: # Only run these if we have a summary
                 # Analyst Agent
                 parallel_tasks.append(
                     self._run_analyst_agent(
                         category=input_data.category,
                         articles=articles_data,
                         summary=news_summary_text,
                         depth=input_data.analysis_depth,
                         financial_data=financial_data_dict,
                         parent_trace=coordinator_trace
                     )
                 )

                 # Fact Checker Agent (optional)
                 if input_data.use_fact_checker:
                     parallel_tasks.append(
                         self._run_fact_checker_agent(
                             articles=articles_data,
                             summary=news_summary_text,
                             max_claims=input_data.max_fact_claims,
                             parent_trace=coordinator_trace
                         )
                     )

                 # Trend Analyzer Agent (optional)
                 if input_data.use_trend_analyzer:
                     parallel_tasks.append(
                         self._run_trend_agent(
                             category=input_data.category,
                             articles=articles_data,
                             parent_trace=coordinator_trace
                         )
                     )
            else:
                 logger.warning("Skipping parallel analysis agents as initial summary is missing.")


            # Execute parallel tasks if any were added
            parallel_results: List[AgentResult] = []
            if parallel_tasks:
                parallel_results = await asyncio.gather(*parallel_tasks)
                agent_results.extend(parallel_results) # Add results to the main list

                # Process parallel results
                for result in parallel_results:
                    if result.success:
                        if result.agent_name == "AnalystAgent":
                            analyst_output: AnalystOutput = result.data
                            analysis_text = analyst_output.analysis
                            logger.info("AnalystAgent completed in parallel run.")
                        elif result.agent_name == "FactCheckerAgent":
                            fact_checker_output: FactCheckerOutput = result.data
                            fact_check_text = fact_checker_output.fact_check_results # Assuming this field name
                            logger.info("FactCheckerAgent completed in parallel run.")
                        elif result.agent_name == "TrendAgent":
                            trend_output: TrendOutput = result.data
                            trends_text = trend_output.identified_trends # Assuming this field name
                            logger.info("TrendAgent completed in parallel run.")
                    else:
                        logger.warning(f"{result.agent_name} failed in parallel run: {result.error}")


            # Step 5: (Optional) Run Writer Agent again to refine summary/markdown with analysis/trends
            # Decide if a second writer pass is needed based on whether new info was generated
            if analysis_text or trends_text:
                 logger.info("Running WriterAgent again to incorporate analysis and trends.")
                 writer_result_final = await self._run_writer_agent(
                     category=input_data.category,
                     articles=articles_data,
                     style=input_data.summary_style,
                     analysis=analysis_text,
                     trends=trends_text,
                     financial_data=financial_data_dict,
                     parent_trace=coordinator_trace
                 )
                 # Replace initial writer result, don't append duplicates
                 agent_results = [res for res in agent_results if res.agent_name != "WriterAgent"] + [writer_result_final]

                 if writer_result_final.success:
                     writer_output_final: WriterOutput = writer_result_final.data
                     news_summary_text = writer_output_final.summary # Update with final summary
                     full_markdown = writer_output_final.markdown # Update with final markdown
                     logger.info("Final summary and markdown generated by WriterAgent.")
                 else:
                     logger.error("Final WriterAgent run failed. Using initial summary/markdown if available.")
                     # Keep the potentially non-None values from the initial run


            # Step 6: Generate Audio (Optional)
            if input_data.generate_audio and news_summary_text:
                logger.info(f"Generating audio with voice: {input_data.voice}")
                try:
                    # Use a nested span for TTS
                    with tracing.span("generate_audio", parent=coordinator_trace) as audio_span:
                        output_filename = f"news_summary_{input_data.category}_{input_data.ticker_symbol or 'general'}.mp3".replace(" ", "_")
                        # Ensure the filename is valid (e.g., replace special chars)
                        output_filename = re.sub(r'[\\/*?:"<>|]', "", output_filename)

                        audio_file_path = text_to_speech(news_summary_text, input_data.voice, output_filename)
                        if audio_file_path:
                            logger.info(f"Audio file generated: {audio_file_path}")
                            audio_span.set_data({"status": "success", "file_path": audio_file_path})
                        else:
                            logger.error("Failed to generate audio file.")
                            audio_span.set_data({"status": "failed"})
                except Exception as e:
                    logger.error(f"Error generating audio: {str(e)}")
                    if coordinator_trace: # Record error at coordinator level if TTS span fails
                        coordinator_trace.set_error({"message": f"Audio generation failed: {str(e)}"})


            # Step 7: Compile final output
            final_output = CoordinatorOutput(
                news_summary=news_summary_text,
                audio_file=audio_file_path,
                markdown=full_markdown,
                analysis=analysis_text,
                fact_check=fact_check_text,
                trends=trends_text,
                financial_data=financial_data_dict,
                graph_files=graph_files_list,
                agent_results=agent_results,
                processing_plan=processing_plan
            )

            # Log completion and add final output to trace
            logger.info("CoordinatorAgent workflow finished.")
            coordinator_trace.set_data({"final_output_summary": final_output.model_dump(exclude={'agent_results'})}) # Log summary, exclude detailed results
            return final_output 
